<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>src.NLP.NLPPredictor.predictor API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.NLP.NLPPredictor.predictor</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import numpy as np
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import gensim
import pickle
import keras
from keras_preprocessing.sequence import pad_sequences


def preprocess_nlp(text):
    &#34;&#34;&#34;

    :param text: plain text
    :return:  preprocessed text
    &#34;&#34;&#34;
    text = text.replace(&#34;\n&#34;, &#34;. &#34;)
    # tokenize the text
    tokens = word_tokenize(text.lower())
    # remove stop words
    stop_words = set(stopwords.words(&#39;english&#39;))
    tokens = [t for t in tokens if t not in stop_words]
    # remove special chars and punctuation
    tokens = [t for t in tokens if t.isalnum()]
    # Remove numbers
    tokens = [t for t in tokens if not t.isdigit()]
    # join the tokens back into a string
    return &#39; &#39;.join(tokens)


def process_split_words(text):
    &#34;&#34;&#34;

    :param text: plain text
    :return: array of tokenized words
    &#34;&#34;&#34;
    result = []
    #nltk.download(&#39;punkt&#39;, quiet=True)  # Download the necessary tokenizer data
    sentences = nltk.sent_tokenize(text)
    for sentence in sentences:
        words = sentence.split()
        result.append(words)
    return result

def predictor(text):
    &#34;&#34;&#34;

    :return: dictionary with frequency of each class appears in the given text
    :param text: plain text
    &#34;&#34;&#34;
    result = process_split_words(text)
    # Load the tokenizer
    # Try abs path if it does not work 
    with open(&#39;/app/src/NLP/NLPPredictor/tokenizer.pkl&#39;, &#39;rb&#39;) as f:
    #with open(&#39;tokenizer.pkl&#39;, &#39;rb&#39;) as f:
        tokenizer = pickle.load(f)
    sequences = tokenizer.texts_to_sequences(result)
    pad_rev = pad_sequences(sequences, maxlen=102, padding=&#39;post&#39;)
    # Try abs path if it does not work
    lstm_model = keras.models.load_model(&#39;/app/src/NLP/NLPPredictor/Bidirectional_LSTM_Model.h5&#39;)
    #lstm_model = keras.models.load_model(&#39;Bidirectional_LSTM_Model.h5&#39;)
    preds = lstm_model.predict(pad_rev)
    classes = []

    for pred in preds:
        if pred[np.argmax(pred)] &gt; 0.5:
            classes.append(np.argmax(pred))

    result = {}
    mapping = [&#39;Data Recipients&#39;, &#39;Safeguards Copy&#39;, &#39;Processing Purpose&#39;,
               &#39;Data Categories&#39;, &#39;Source of Data&#39;, &#39;Right to Erase&#39;,
               &#39;Right to Restrict&#39;, &#39;Right to Access&#39;, &#39;Right to Object&#39;,
               &#39;Withdraw Consent&#39;, &#39;Right to Portability&#39;, &#39;Profiling&#39;,
               &#39;Controller Contact&#39;, &#39;Provision Requirement&#39;,
               &#39;Storage Period&#39;, &#39;Lodge Complaint&#39;, &#39;DPO Contact&#39;,
               &#39;Adequacy Decision&#39;]
    for cat in mapping:
        result[cat] = 0
    for c in classes:
        result[mapping[c]] = 1
    return result


if __name__ == &#39;__main__&#39;:
    #preds = process_split_words(&#34;sd asd awd  awfawf  saffaw. awda awd s d wad ? adwuidandnwda adina dawd, awdjajwd.&#34;)
    preds = predictor(&#34;We may provide our analysis and certain non-personal information to third parties who may in turn use this information to provide advertisements tailored to your interests. We seek to maintain the integrity and security of your Personal Information. In order to improve guest online and mobile shopping experiences, help with fraud identification. These contracts give your personal data the same protection it has in the EEA. We may share some or all of your personal data with our affiliates.&#34;)
    print(preds)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.NLP.NLPPredictor.predictor.predictor"><code class="name flex">
<span>def <span class="ident">predictor</span></span>(<span>text)</span>
</code></dt>
<dd>
<div class="desc"><p>:return: dictionary with frequency of each class appears in the given text
:param text: plain text</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def predictor(text):
    &#34;&#34;&#34;

    :return: dictionary with frequency of each class appears in the given text
    :param text: plain text
    &#34;&#34;&#34;
    result = process_split_words(text)
    # Load the tokenizer
    # Try abs path if it does not work 
    with open(&#39;/app/src/NLP/NLPPredictor/tokenizer.pkl&#39;, &#39;rb&#39;) as f:
    #with open(&#39;tokenizer.pkl&#39;, &#39;rb&#39;) as f:
        tokenizer = pickle.load(f)
    sequences = tokenizer.texts_to_sequences(result)
    pad_rev = pad_sequences(sequences, maxlen=102, padding=&#39;post&#39;)
    # Try abs path if it does not work
    lstm_model = keras.models.load_model(&#39;/app/src/NLP/NLPPredictor/Bidirectional_LSTM_Model.h5&#39;)
    #lstm_model = keras.models.load_model(&#39;Bidirectional_LSTM_Model.h5&#39;)
    preds = lstm_model.predict(pad_rev)
    classes = []

    for pred in preds:
        if pred[np.argmax(pred)] &gt; 0.5:
            classes.append(np.argmax(pred))

    result = {}
    mapping = [&#39;Data Recipients&#39;, &#39;Safeguards Copy&#39;, &#39;Processing Purpose&#39;,
               &#39;Data Categories&#39;, &#39;Source of Data&#39;, &#39;Right to Erase&#39;,
               &#39;Right to Restrict&#39;, &#39;Right to Access&#39;, &#39;Right to Object&#39;,
               &#39;Withdraw Consent&#39;, &#39;Right to Portability&#39;, &#39;Profiling&#39;,
               &#39;Controller Contact&#39;, &#39;Provision Requirement&#39;,
               &#39;Storage Period&#39;, &#39;Lodge Complaint&#39;, &#39;DPO Contact&#39;,
               &#39;Adequacy Decision&#39;]
    for cat in mapping:
        result[cat] = 0
    for c in classes:
        result[mapping[c]] = 1
    return result</code></pre>
</details>
</dd>
<dt id="src.NLP.NLPPredictor.predictor.preprocess_nlp"><code class="name flex">
<span>def <span class="ident">preprocess_nlp</span></span>(<span>text)</span>
</code></dt>
<dd>
<div class="desc"><p>:param text: plain text
:return:
preprocessed text</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def preprocess_nlp(text):
    &#34;&#34;&#34;

    :param text: plain text
    :return:  preprocessed text
    &#34;&#34;&#34;
    text = text.replace(&#34;\n&#34;, &#34;. &#34;)
    # tokenize the text
    tokens = word_tokenize(text.lower())
    # remove stop words
    stop_words = set(stopwords.words(&#39;english&#39;))
    tokens = [t for t in tokens if t not in stop_words]
    # remove special chars and punctuation
    tokens = [t for t in tokens if t.isalnum()]
    # Remove numbers
    tokens = [t for t in tokens if not t.isdigit()]
    # join the tokens back into a string
    return &#39; &#39;.join(tokens)</code></pre>
</details>
</dd>
<dt id="src.NLP.NLPPredictor.predictor.process_split_words"><code class="name flex">
<span>def <span class="ident">process_split_words</span></span>(<span>text)</span>
</code></dt>
<dd>
<div class="desc"><p>:param text: plain text
:return: array of tokenized words</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process_split_words(text):
    &#34;&#34;&#34;

    :param text: plain text
    :return: array of tokenized words
    &#34;&#34;&#34;
    result = []
    #nltk.download(&#39;punkt&#39;, quiet=True)  # Download the necessary tokenizer data
    sentences = nltk.sent_tokenize(text)
    for sentence in sentences:
        words = sentence.split()
        result.append(words)
    return result</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.NLP.NLPPredictor" href="index.html">src.NLP.NLPPredictor</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="src.NLP.NLPPredictor.predictor.predictor" href="#src.NLP.NLPPredictor.predictor.predictor">predictor</a></code></li>
<li><code><a title="src.NLP.NLPPredictor.predictor.preprocess_nlp" href="#src.NLP.NLPPredictor.predictor.preprocess_nlp">preprocess_nlp</a></code></li>
<li><code><a title="src.NLP.NLPPredictor.predictor.process_split_words" href="#src.NLP.NLPPredictor.predictor.process_split_words">process_split_words</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>